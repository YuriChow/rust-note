安全、有效地处理并发编程是 ***Rust*** 的另一个重要目的。***Concurrent programming(并发编程)***，程序的不同部分 独立执行，***parallel programming(并行编程)***，程序的不同部分 同时执行，越来越重要，因为其可以享受多处理器带来的优势，历史上，在这种上下文中编程非常困难且易于发生错误：***Rust*** 期望能够改变这种情况。   
开始 ***Rust*** 团队认为 保证内存安全 和 阻止并发问题 是两个不同的挑战，需要使用不同的方法解决。后来团队发现 **ownership** 和 **类型系统** 是一对强有力的工具 来帮助管理内存安全 和 并发问题！通过借力 ownership 和 类型检查，***Rust*** 中许多并发错误是 编译时错误，而不是运行时错误。因此，错误的代码会直接拒绝编译并打印一个错误解释相关问题，而不是让你花大量的时间尝试复现 发生运行时异常 时的 确切环境情况。因此你可以在你开发时就修改你的代码，而不是将错误一直隐藏到发布。我们(***Rust*** 团队)给 ***Rust***  的这个特色绰号为 ***fearless concurrency(无畏并发)***。无畏并发允许你在远离潜在 bugs 并且易于重构且不会引入新 bugs 的条件下 写代码。   
本章中，为了简单起见，将许多问题表示为 concurrent 而不是更精确的说是 concurrent 和/或 parallel。当之后提到 “concurrent” 或 “并发”，请在脑中自动替换 concurrent 和/或 parallel。      
许多编程语言对于他们提供的为了 处理并发问题 的方案都是十分教条的。例如，***Erlang*** 拥有非常优雅的功能用来进行 消息传递并发，但是在线程间分享状态的方法却十分模糊。只提供问题解决方案的一个子集对于高阶编程语言是一个合理的战略，因为高阶编程语言放弃了一些控制来获得抽象。然而，低阶编程语言被期望提供 在任何给定情况下的最优性能方案，并且拥有更少的硬件抽象。      
***concurrent(并发)*** 和 ***parallel(并行)*** 的区别:
   - 并发：多任务在单 CPU 上交替执行，对 CPU 来说，仍然是按小代码段进行穿行执行。想象两队人，轮流使用一台咖啡机接咖啡；
   - 并行：区别于串行，多任务真正分配到不同的 CPU 内核上去执行。想象两队人，各自在两台同时排队接咖啡；   


# 使用 Threads 来同时运行代码
在绝大多数目前的操作系统中，一个可执行程序的代码是运行在 ***process(进程)*** 中的，并且操作系统同时管理多个进程。你的程序中，也可以有同时运行的独立部分，这个特性叫做 ***threads(线程)***。
1. 将程序中的计算分为多个线程可以显著提升性能，但是也增加了复杂性，因为对于在不同线程上的子代码段按怎样的顺序执行，没有任何固有担保。这可能会造成以下的问题：
   - **Race conditions**，条件竞赛，线程们以不一致的顺序访问数据或资源；
   - **Deadlocks**，死锁，两个线程都在等对方 完成对方拥有的资源的使用，同时阻碍了两个线程继续运行；
   - 一些只有在特殊情境下发生的 Bugs，并且十分难以复现 和 完全修复。
2. 编程语言使用多种不同方式实现多线程，许多操作系统提供创建新线程的 API。编程语言调用操作系统提供的 API 来创建新线程的模式有时被叫做 ***1:1***，意思是 一个操作系统线程/一个语言线程，暨 每一个语言线程 一个操作系统线程。Rust 标准库仅提供了一个 ***1:1*** 的实现。也有其他的 crate 实现了其他的线程创建模式，做了不同的取舍。

## 使用 `spawn` 创建一个新线程
创建一个新线程，导入 `use std::thread;` 调用 `thread::spawn` 函数，并且传入一个 包含我们希望在新线程上运行的代码的 闭包。例如：
```rust
use std::thread;
use std::time::Duration;
fn main() {
   let handle = thread::spawn(|| {
      for i in 1..30 {
         println!("number {} from the spawned thread!", i);
         thread::sleep(Duration::from_millis(1));
         if i == 29 {
            println!("Spawned thread finished");
         }
      }
   });
   for i in 1..15 {
      pritnln!("number {} from the main thread!");
      thread::sleep(Duration::from_millis(1));
   }
   println!("Main thread finished!");
}
```
1. 注意这个函数：当主线程结束的时候，新线程就会停止，无论新线程是否完成运行。
2. 运行多次，注意输出，程序是**无法保证 主线程 和 新线程 的运行顺序**的，几乎每次都不同，并且还和操作系统管理线程的方式有关。
3. 如果运行代码你只看到了主线程的输出，或者没看到任何线程输出重叠，增加循环的范围，提高切换线程的概率。

## 使用 `join` ***Handles(句柄)*** 等待所有线程结束
1. 前面的代码，不仅由于主线程的结束导致派生线程过早停止，而且也完全不能保证派生线程能够运行，因为对于各线程的运行顺序，没有任何担保。
2. 通过保存 `thread::spawn` 的返回值到一个变量中，我们可以修改这个派生线程没能运行或者过早停止的问题，这个返回值类型是 `JoinHandle`，一个 `JoinHandle` 是一个被拥有的值，当我们调用其中的 `.join()` 方法，它将会等待它的线程完成。以下代码展示了用法，保证派生线程在 `main` 结束前完成：
   ```rust
   fn main() {
      let handle = thread::spawn {};
      // -------- snip -------
      handle.join().unwrap();
   }
   ```   
   调用句柄上的 `join` 阻塞了当前正在运行的线程(也就是 `join` 调用代码位置所在的线程)，直到其代表的线程完成执行。***Blocking(阻塞)*** 一个线程意味着那个线程被阻止 **继续执行工作 或者 退出**。
3. 小细节，调用 `join` 的位置会影响你的线程是不是同时运行的，比如把主线程中 `join` 语句紧接着其代表线程的声明，会导致这个线程对于主线程来说就相当于是单线程的，没有同时执行。

## 在线程中使用 `move` 闭包
`move` 关键字经常配合 被传入 `thread::spawn` 中的闭包 使用，因为闭包将会夺走 其使用的 环境中的值的 ownership，因此用来将那些值的 ownership 从一个线程传递到另一个线程。在 [[11-函数式编程语言特性：迭代器和闭包]] 中，我们在闭包的上下文中讨论了 `move`。现在，我们聚焦于 `move` 和 `thread::spawn` 间的交互。
1. 当我们在传入派生线程的闭包中 使用环境中的变量的时候，如果不加任何处理，则无法编译通过，如下：
   ```rust
   let v = vec![1, 2, 3];
   let handle = thread::spawn(|| {
      println!("Here's a vector: {:?}", v);
      // error[E0373]: closure may outlive the current function, but it borrows `v`, which is owned by the current function
   });
   ```    
   ***Rust*** 会推断 变量 `v` 是如何被捕获的，并且，因为 `println!` 只需要 `v` 的引用，闭包尝试借用 `v`。然而，现在有一个问题：***Rust*** 无法知道派生线程会运行多久，因此他不知道 `v` 的引是否将会永远有效。比如我们在主线程中手动 `drop(v)`，这个时候派生线程中的 `v` 的引用就失效了，但是可能派生线程 还没执行完，依旧需要使用这个引用。使用 编译器 提示方法可以修复这个问题：
   ```rust
   let handle = thread::spawn(move || {
      // -------- snip -------
   });
   ```   
   通过在闭包前增加 `move` 关键字，我们强制闭包夺走其使用的 环境变量的 ownership 而不是允许 ***Rust*** 来推断出 “应该是借用那个环境变量”。并且由于 `v` 的 ownership 被移入闭包，因此失效，不再可以访问。
2. 正常在派生线程闭包的开始使用 `let new_var = env_var;`，将环境变量移入闭包也是可以的。但是如果需要操作的变量很多，不如直接使用 `move` 来得直接不易错。因此还是**推荐使用 `move` 关键字，对所有情况使用这同一种更安全的方式处理**。


# 使用 *Message Passing(信息传递)* 来在线程间传输数据
一个越来越流行的保证并发安全的处理是 ***message passing(信息传递)***，线程 或 ***actors(轻量级进程)*** 通过互相传递包含数据的信息来进行交流。一个来源于 [*the* ***Go*** *language documentation*](https://golang.org/doc/effective_go.html#concurrency) 标语的观点：别通过 共享内存 来 交流；反而，通过交流 来 共享内存。
1. ***Rust*** 拥有的一个为了完成 **消息传递并发** 的主要工具是 ***channel(通道)***，一个 ***Rust*** 标准库提供了一个实现的 编程概念。你可以将一个 编程中的通道 想象为 像是一个水的通道，例如 一条小溪 或者 一条河，如果你在小溪中放了一个橡皮鸭或者船，它会向下漂流直到河道的尽头。
2. 编程中 一个通道 有两半：一个***发射端(transmitter)*** 和 一个***接收端(receiver)***。发射端部分是上游(你放“橡皮鸭”的地方)，接收端是下游(接受“橡皮鸭”的地方)。你的代码的一部分调用发射端的方法将数据传出，并且另一部分检测接收端收到的信息。如果这两半 任意一半 dropped 了，则这个通道 ***closed(关闭)***。
3. 我们会编程 一个线程生成值 发送给另一个线程中 来打印。一旦你熟悉了这个技术，就可以使用通道实现一个聊天系统 或者 一个许多线程执行一部分计算然后发给另一个线程来整合结果的系统。
4. `use std::sync::mpsc;` `mpsc` 是 ***multiple producer, single consumer*** 的缩写。简单地说，***Rust*** 标准库实现通道的方法意味着：一个通道可以拥有多个发送端 生成值，但是只有一个接收端来消耗那些值。
5. `mpsc::channel()` 返回一个元组，第一个元素是 发送端 - `tx`，第二个元素是 接收端 - `rx`。
6. 让派生线程 **拥有**通道的发送器端 使其能够通过通道发送信息。
7. 调用 `tx.send(some_msg)` 发送数据，这个方法返回一个 `Result<T, E>` 类型，如果接收端已经被 dropped 了，发送的值没有接收方，这个操作会返回一个 error，在实际项目中，我们应该合适的处理 `Result<T, E>` 类型数据，不再赘述。
8. 通道的 接收器端 有两个有用的方法：`recv` 和 `try_recv`。
   - `recv` 就是 receive 的缩写，将会阻塞主线程执行，等待直到接收到一个值。当一个值被发送，`recv` 将会这个值返回为 `Result<T, E>`。**当发送端关闭了，`recv` 将会返回一个 error 来表示不会再有数据传来了**。
   - `try_recv` 方法不会阻塞，但是会立即返回一个 `Result<T, E>` 值：如果当时有可获得的信息，将其包装在 `Ok` 中返回；**如果当时没有任何信息，返回 `Err`**。当你的线程在等信息的同时还有其他工作要做：我们应该写一个 `loop` 经常调用 `try_recv`，如果收到信息就处理，如果没有就做会儿其他工作，直到下次检查。
9. 示例代码：
   ```rust
   use std::thread;
   use std::time::Duration;
   use std::sync::mpsc;
   fn main() {
      let (tx, rx) = mpsc::channel();
      let tx1 = tx.clone();
      thread::spawn(move || {
         let vals = vec![
            String::from("hi"),
            String::from("from"),
            String::from("the"),
            String::from("thread"),
         ];
         for v in vals {
            tx1.send(val).unwrap();
            thread::sleep(Duration::from_millis(1));
         }
      });
      let tx = tx.clone();
      thread::spawn(move || {
         let vals = vec![
            String::from("hi"),
            String::from("from"),
            String::from("the"),
            String::from("thread"),
         ];
         for v in vals {
            tx.send(val).unwrap();
            thread::sleep(Duration::from_millis(1));
         }
      });
      for received in rx {
         println!("Got: {}", reveived);
      }
   }
   ```

## 通道和所有权传输
所有权规则在信息传递中起到了至关重要的作用，因为它帮助你写出安全的并发代码。防止 并发编程错误 是贯穿程序地考虑所有权带来的优势。在一个值 `val` 被 `tx.send(val).unwrap()` 之后，这个方法会夺走这个值的所有权，这样，这个线程中，这个代码之后 `val` 失效，无法访问。允许继续访问是一个非常坏的想法：一旦值被传入另一个线程中，在我们在本线程中再次使用那个值之前，另外的那个线程可以修改甚至 drop 这个值，这会造成错误或者预期外的结果由于数据不存在或者不匹配。因此 ***Rust*** 通过通道和所有权系统阻止了这种情况的发生，并且这种错误是编译时错误。

## 发送多个值然后观察接收端等待
发送多个数据，会使 `rx` 变成一个 `Receiver<String>` 类型的迭代器，通过 `for ... in ...` 来遍历。并且这个迭代器中有阻塞，在遇到 `None` 之前都不会跳出循环，而是会暂停等待新数据到来再继续执行循环。

## 通过克隆发送端创建多生产端
早先我们提到了通道是 `mpsc` 意味着 多生产端单消费端，我们可以通过 克隆发送端 来创建多个 接收端相同的 发送端。但是注意，多线程里的多个发送端，是无法保证数据到达的顺序的。


# 共享状态并发
消息传递并发是一个处理并发的不错的方式，但是并不是唯一的方式。回忆一下 ***Go*** 的标语：别通过 共享内存 来 交流。那么通过共享内存来交流的代码长什么样？又是因为什么，消息传递并发的狂热者要反着来。某种程度上，任何语言中的 通道技术 都类似于 单所有权，因为一旦你将值放进通道传走，你就无法(在本线程)再使用它了。而共享内存式并发像是多所有权：多个线程可以同时访问同一个内存地址。如 [[13-智能指针]] 所讲，智能指针使其成为可能。多所有权会增加系统复杂性，因为需要管理这些不同的所有者，***Rust*** 的类型系统和所有权规则极大得协助了正确管理不同的所有者。

## 使用 ***Mutexes*** 来允许每次从单个线程访问数据
***Mutex(互斥锁)*** 是 ***mutual(互) exclusion(斥)*** 的缩写，一个互斥锁在任何给定时间点仅允许一个线程访问某些数据。为了访问互斥锁中的数据，一个线程必须首先 通过请求获得互斥锁的锁 来 示意它希望访问数据。锁是一个数据结构，是互斥锁用来追踪目前谁在访问数据 的部分。因此互斥锁被描述为通过锁系统来守卫它持有的数据。
1. 互斥锁有着“很难用”的名声，因为你需要记住两点规则：
   1. 在使用数据前，你必须尝试获得锁；
   2. 当你使用完互斥锁守卫的数据以后，你必须解锁数据，这样其他的线程才能够获取锁；
2. 正确的管理互斥锁非常棘手，因此非常多的人更喜欢通道。然而，多谢 ***Rust*** 的类型系统和所有权规则，你无法错误地锁/解锁。
### `Mutex<T>` 的 API
```rust
use std::sync::Mutex;
fn main() {
   let m = Mutex::new(5);
   {
      let mut num = m.lock().unwrap();
      *num = 6;   
   }
   println!("m = {:?}", m);
}
```
1. `use std::sync::Mutex;` 导入 `Mutex`。使用 `let m = Mutex::new(5);` 创建互斥锁对象。为了访问互斥锁中的数据，使用 `m.lock()` 获得锁。这个调用会**阻塞当前线程 直到轮到我们拥有 锁**。如果其他正在持有锁的线程 panicked 了，互斥器会处于 ***poisoned(中毒) 状态***，`lock` 的调用会失败，在这种情况下，没有任何一个线程能够获得锁，因此我们选择直接 `.unwrap()` 解包 `lock` 调用的返回值，出问题就让这个线程 panic 就好。
2. 在我们获得锁以后，我们可以处理返回值，示例程序中使用 `let mut num = ` 使 `num` 成为内部值的一个可变引用。类型系统保证了我们在使用 `m` 中的值之前必须获得锁: `Mutex<i32>` 并不等于 `i32`，因此我们必须获得锁来使用 i32 值。
3. 就如你猜想的一样，`Mutex<i32>` 也是一个智能指针。更准确地讲，调用 `lock` 返回一个智能指针 `MutexGuard`，被包装在一个 `LockResult` 中(具体为 `Result<MutexGuard<i32>, PosionError<MutexGuard<i32>>>`)，也就是我们使用 `unwrap` 的地方。`MutexGuard` 智能指针实现了 `Deref` 特性指向其内部的数据；并且也实现了 `Drop` 特性，当一个 `MutexGuard` 离开作用域 自动释放锁，因此我们没有冒着 忘记释放锁并且阻塞互斥锁被其他线程使用 的风险，因为锁会被自动释放。
### 在多线程间共享互斥锁 & 多线程中的多所有权
当我们试图在线程间共享 `Mutex<T>` 的时候，由于 `move` 的存在，会导致互斥锁对象的 ownership 被传入到第一个使用的线程中。因此自然想到使用 `Rc<T>` 来包裹互斥锁，获得多引用的能力，但是不幸的是，`Rc<T>` 跨线程传递不安全，当 `Rc<T>` 管理引用计数时，它在每次调用 `clone` 的时候增加引用计数 并且 当引用 dropped 的时候减少引用计数，但是它没有使用任何 ***(concurrency primitives)并发原语*** 来保证 计数器的改变不会被其他线程打断，这可能会导致错误计数 - 一个难以察觉的 bug，可能会导致内存泄漏 或者 一个值在我们还需要使用它之前提前被 drop 掉。我们需要的是一个功能像 `Rc<T>` 但是改变引用计数器的方式更加线程安全的类型。
### 原子引用计数 - `Arc<T>` 
幸运的是，`Arc<T>` 就是一个类似于 `Rc<T>` 的类型，并且并发情况下使用十分安全。***a - atomic(原子的)***，表示为 ***atomically reference counted(原子引用计数)*** 类型。atomics 是一种额外的并发原语，详细信息查询 [std::sync::atomic](https://doc.rust-lang.org/std/sync/atomic/index.html)，现在你只需要知道 atomics 功能和基本类型一样，但是跨线程分享是安全的。   
1. 你可能好奇为什么基本数据类型不是 atomic 的，并且为什么标准库不默认使用 `Arc<T>` 来实现。这是因为**线程安全伴随着 性能损耗**，而这个性能损耗 只有 你希望 当你真正需要的时候再付出，如果单线程编程，则是完全没作用的性能浪费。
2. `Arc<T>` 和 `Rc<T>` 拥有相同的 API
3. 因此修改后的代码如下：
   ```rust
   use std::sync::{Arc, Mutex};
   use std::thread;
   fn main() {
      let counter = Arc::new(Mutex::new(0));
      let mut handles = vec![];
      for _ in 0..10 {
         let counter = Arc::clone(&counter);
         let handle = thread::spawn(move || {
            let mut num = counter.lock().unwrap();
            *num += 1;
         });
         handles.push(handle);
      }
      for handle in handles {
         hadle.join().unwrap();
      }
      println!("Result: {}", *counter.lock().unwrap());
   }
   ```

## `RefCell<T>/Rc<T>` 和 `Mutex<T>/Arc<T>` 之间的相似性
你可能已经发现了 `counter` 是不可变的，但是我们能够获得一个其内部值的可变引用，这意味着 `Mutex<T>` 提供了 ***inerior mutability(内部可变)***，和 `Cell` 系列一样，就像我们 [[13-智能指针]] 中使用的 `RefCell<T>` 允许我们修改 `Rc<T>` 的内部值一样，我们可以使用 `Mutex<T>` 来修改 `Arc<T>` 的内部值。      
另一个细节值得注意，当你使用 `Mutex<T>` 的时候 ***Rust*** 无法保护你不犯任何一个逻辑错误。比如 [[13-智能指针]] 中讲的循环引用造成内存泄漏。类似的，`Mutex<T>` 有创造 ***deadlock(死锁)*** 的风险，发生在：当一个操作 需要锁住两个资源，并且两个线程各拥有一个已获得的锁，导致他们永远互相等待。


# 使用 `Sync` & `Send` 特性实现可扩展并发

^Extensible-Concurrency-with-the-Sync-and-Send-Traits

有趣的是，***Rust*** 语言只有很少的并发特性。几乎每个目前为止我们在本章中提及的并发特性都已经是标准库的一部分，而不是语言。你处理并发的选择 不局限于语言或者标准库，你可以写自己的并发特性或者使用别人写的。然而，两个并发概念被嵌入了语言：`std::marker` 特性 `Sync` 和 `Send`。

## 使用 `Send` 允许跨线程传输所有权
1. `Send` 标识特性表明，实现了 `Send` 的类型的值的 ownership 可以在线程间被传递。
2. 几乎每个 ***Rust*** 类型都是 `Send`。但是有一些例外，包括 `Rc<T>`：不能被 `Send`，因为如果你克隆了一个 `Rc<T>` 值，并且尝试把克隆体的 ownership 传到另一个线程，两个线程可能会在同一时间更新 引用计数器。由于这个原因，`Rc<T>` 被实现为在单线程情况中使用，这里不希望支付维护线程安全带来的额外性能开销。因此 ***Rust*** 的类型系统 和 特性约束 保证了你永远不可能意外地将一个 `Rc<T>` 值跨线程不安全传输。有这种需求时应该使用 `Arc<T>` 代替 `Rc<T>`。
3. 任何完全由 `Send` 类型组成的类型，也自动被标记为 `Send`。几乎所有基本数据类型都是 `Send`，除了 ***raw pointer(原始指针)***，[[17-高级功能]] 中会讲。

## 使用 `Sync` 允许多线程访问
1. `Sync` 标识特性表明，实现了 `Sync` 特性的类型的值被多线程引用 是安全的(暨 `&T` 是 `Send`)。换句话说，任何类型 `T`，如果 `&T` 是 `Send`，那么 `T` 是 `Sync`，意味着引用可以被安全地发送到另一个线程。
2. 类似于 `Send`，基本数据类型是 `Sync`，并且任何完全由 `Sync` 类型组成的类型，也是 `Sync`。
3. 智能指针 `Rc<T>` 同样也不是 `Sync`，原因和其不是 `Send` 的原因相同。`RefCell<T>` 类型是 `Cell<T>` 类型家族的，也不是 `Sync`。`RefCell<T>` 使用的 运行时借用检查的实现 **不是线程安全的**。如前一章所讲，智能指针 `Mutex<T>` 是 `Sync`，能够用来多线程共享使用权。

## 手动实现 `Send` 和 `Sync` 是 **不安全的**
由于由 `Send` 和 `Sync` 组成的类型自动的也是 `Send` 和 `Sync`，我们不需要手动实现那些特性。作为一个 标记特性，他们甚至没有相关方法来实现，只是用于强制并发相关的不变性。手动实现这些特性引入了实现不安全的 ***Rust*** 代码。[[17-高级功能]] 我们会讨论使用 不安全 ***Rust*** 代码，目前，重要信息是：创建不是全部由 `Send` 和 `Sync` 部分组成的 新并发类型要求仔细地思考 来维护安全担保。查阅 [The Rustonomicon](https://doc.rust-lang.org/nomicon/index.html) 获取更多关于这些担保的信息，和如何维护。   
注意：由于 ***Rust*** 处理并发和语言关系很小，因此很多并发解决方案被实现为 crates，这些箱可能会比标准库更快，记得随时查询 最当下、最先进(state-of-the-art) 的箱来在多线程任务中使用。


# 代码
- ***Rust/multi_thread_learn/src/main.rs***
- ***Rust/multi_thread_with_move_learn/src/main.rs***
- *Rust/channel_learn/src/main.rs*
- ***Rust/mutex_learn/src/main.rs***